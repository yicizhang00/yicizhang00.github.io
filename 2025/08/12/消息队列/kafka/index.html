<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>kafka | Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="kafka"><meta name="application-name" content="kafka"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="kafka"><meta property="og:url" content="http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/index.html"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="初步概念Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调^1的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm&amp;amp;"><meta property="og:locale" content="en"><meta property="og:image" content="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg"><meta property="article:author" content="John Doe"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg"><meta name="description" content="初步概念Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调^1的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm&amp;amp;"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/"><link rel="preconnect" href="//cdn.cbd.int"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: {"enable":true,"img":"https://upload-bbs.miyoushe.com/upload/2024/07/27/125766904/ba62475f396df9de3316a08ed9e65d86_5680958632268053399..png"},
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: undefined,
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"Author: John Doe","link":"Link: ","source":"Source: Hexo","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.","copySuccess":"Copy success, copy and reprint please mark the address of this article"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"Traditional Chinese Activated Manually","cht_to_chs":"Simplified Chinese Activated Manually","day_to_night":"Dark Mode Activated Manually","night_to_day":"Light Mode Activated Manually","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: 'Hexo',
  title: 'kafka',
  postAI: '',
  pageFillDescription: '初步概念, 消息订阅模式, 1. 点对点模式（Point-to-Point Queue 模式）, 设计架构, 存储布局, Partition结构, message结构, 存储策略, 定位消息, 综合时间复杂度, 数据访问流程（存储角度）, 生产者生产, 消费者消费, 高效传输, 无状态 broker, 分区协调, 分发保障, kafka性能测试, Producer 测试, Consumer 测试, kafka的缺陷, 1. 跨分区无法保证全局顺序, 2. 没有内置死信队列（DLQ）, 3. 至少一次投递（可能重复消费）, 4. 消息延迟感知受限, 5. 单分区性能受限, 6. 存储依赖 Broker 磁盘【已解决】, 7.重复生产【已解决】, 未来的计划（原论文均已实现）初步概念是最初由公司开发是一个分布式支持分区的多副本的基于协调的分布式消息系统它的最大的特性就是可以实时的处理大量数据以满足各种需求场景比如基于的批处理系统低延迟的实时系统流式处理引擎日志访问日志消息服务等等从早期的论文可以看出最初是设计用于处理大量数据日志的消息订阅模式点对点模式模式特点一个消息只能被一个消费者接收生产者把消息发送到队列里多个消费者竞争消费但每条消息只会被其中一个消费掉应用场景任务分发工作队列例子假设用发布订阅模式特点消息会广播给所有订阅者生产者发消息到所有订阅该的消费者都能收到应用场景新闻推送通知广播多服务监听例子设计架构的数据流的特殊格式为主题一个消费者从经纪人在这里是的实例可以订阅一个或者多个要发布一个消息生产者可以使用类型意味着由生产者决定如何序列化并且发布到指定的上要订阅一个主题消费者首先会为该主题创建一个或多个消息流发布到该主题的消息会被均匀地分配到这些子流中每个消息流都提供了一个迭代器接口用于遍历源源不断产生的消息消费者随后通过遍历流中的每一条消息来处理其载荷与传统迭代器不同消息流迭代器永远不会终止如果当前没有新的消息可供消费迭代器会阻塞直到有新的消息发布到该主题即生产者消息的产生者是消息的入口是实例每个服务器上有一个或多个的实例我们姑且认为每个对应一台服务器每个集群内的都有一个不重复的编号如图中的等消息的主题可以理解为消息的分类的数据就保存在在每个上都可以创建多个的分区每个可以有多个分区分区的作用是做负载提高的吞吐量同一个在不同的分区的数据是不重复的的表现形式就是一个一个的文件夹每一个分区都有多个副本副本的作用是做备胎当主分区故障的时候会选择一个备胎上位成为在中默认副本的最大数量是个且副本的数量不能大于的数量和绝对是在不同的机器同一机器对同一个分区也只可能存放一个副本包括自己每一条发送的消息主体消费者即消息的消费方是消息的出口我们可以将多个消费组组成一个消费者组在的设计中同一个分区的数据只能被消费者组中的某一个消费者消费同一个消费者组的消费者可以消费同一个的不同分区的数据这也是为了提高的吞吐量集群依赖来保存集群的的元信息来保证系统的可用性存储布局具有非常简单的存储布局一个主题的每个分区对应一个逻辑日志在物理层面上一个日志被实现为一组大小大致相同的段文件例如每当生产者向某个分区发布消息时只需将该消息追加写入最后一个段文件为了获得更好的性能段文件并不是每写一次就刷盘而是在发布了可配置数量的消息或者经过了一定时间后才会刷盘到磁盘只有当消息被刷盘后它才会对消费者可见与典型的消息系统不同中存储的消息没有显式的消息相反每条消息通过其在日志中的逻辑偏移量来寻址这样避免了维护额外的需要频繁随机访问的索引结构将消息映射到消息实际位置的开销需要注意的是我们的消息是递增的但不是连续的要计算下一条消息的我们需要将当前消息的长度加到它的上从此以后我们会将消息和偏移量交替使用消费者始终顺序地消费某个分区中的消息如果消费者确认了某个消息的偏移量就意味着它已经收到了该分区中该偏移量之前的所有消息在底层消费者会向发送异步的拉取请求以便提前准备好一批数据供应用消费每个拉取请求包含开始消费的消息偏移量可接受的最大字节数每个在内存中维护一个已排序的偏移量列表包括每个段文件中第一条消息的偏移量会通过查找该偏移量列表定位到所请求的消息所在的段文件并将数据返回给消费者当消费者收到一条消息后会计算出下一条消息的偏移量并在下一次拉取请求中使用它结构每个可以划分为一个或者多个在服务器上的表现为一段连续的磁盘存储每个下有多个文件每个包含文件文件文件其中文件为具体的消息和为索引偏移量索引每个都有一个文件它是一个稀疏索引记录逻辑物理文件位置的映射并不会为每条消息建立索引而是隔固定字节数默认约写入一条索引查找时先在索引文件里二分查找找到最接近的对应的物理位置再顺序扫描到目标消息时间戳索引每个还有一个文件用于记录时间戳物理文件位置的映射查找消息时如果用户按时间查找会在这个文件里二分查找定位大致位置然后再回到文件日志文件扫描是辅助查询的稀疏索引而文件是真正的记录要查找需要经过稀疏索引的二次跳转例如查找为的物理位置先找到的所在的文件利用二分法查找这里找到的就是在第二个文件打开找到的中的文件也就是文件该文件起始偏移量为我们要查找的为的在该内的偏移量为所以这里要查找的相对为由于该文件采用的是稀疏索引的方式存储着相对及对应物理偏移量的关系所以直接找相对为的索引找不到这里同样利用二分法查找相对小于或者等于指定的相对的索引条目中最大的那个相对所以找到的是相对为的这个索引根据找到的相对为的索引确定存储的物理偏移位置为打开数据文件从位置为的那个地方开始顺序扫描直到找到为的那条这套机制是建立在为有序的基础上利用有序稀疏索引二分查找顺序查找等多种手段来高效的查找数据结构在中每条消息被封装成一个存储在的中主要包含以下部分字段含义分区内的唯一序号标识消息在分区中的位置消费者依赖它来跟踪消费进度可选用于分区路由根据选择消息的实际内容即业务数据消息的时间戳创建时间或日志时间可选用于时间索引可选的元数据用于存储附加信息比如消息类型等校验码用于检测消息在存储或传输过程中的损坏注意引入了批量消息为了减少磁盘会把多条消息打包存储在同一段日志中存储策略支持两种策略删除旧消息按时间保留最近毫秒的消息超过则删除默认为天按大小保留日志总大小超过则删除最老的压缩策略对于有的消息同一个只保留最新的消息适合状态消息去重场景定位消息假设要读取的消息定位用的列表找到包含的因为按排序可以用二分查找时间复杂度数量查找在内的位置通过索引稀疏索引先定位到最接近的索引索引查找可视作二分查找时间复杂度内索引条目数然后从索引位置向前或向后扫描若干条消息找到确切最多扫描条消息稀疏索引步长通常对应条消息这个可以视为常数级操作读取消息消息在文件中是顺序存储的找到位置后直接从页缓存或磁盘读取顺序非常快综合时间复杂度查找查找内总复杂度接近读取消息顺序通常视为在页缓存命中情况下实际上数量和内索引条目数都非常小通常条左右所以查找非常快数据访问流程存储角度写消息到分区写入页缓存顺序写定期刷新页缓存到磁盘或者由操作系统异步刷盘拉消息从页缓存读取消费后提交生产者生产消息写入后是主动的去进行同步的采用模式将数据发布到每条消息追加到分区中顺序写入磁盘所以保证同一分区内的数据是有序的写入示意图如下分区的主要目的是方便扩展因为一个可以有多个所以我们可以通过扩展机器去轻松的应对日益增长的数据量提高并发以为读写单位可以多个消费者同时消费数据提高了消息的处理效率熟悉负载均衡的朋友应该知道当我们向某个服务器发送请求的时候服务端可能会对请求做一个负载将流量分发到不同的服务器那在中如果某个有多个又怎么知道该将数据发往哪个呢中有几个原则在写入的时候可以指定需要写入的如果有指定则写入对应的如果没有指定但是设置了数据的则会根据的值出一个如果既没指定又没有设置则会轮询选出一个保证消息不丢失是一个消息队列中间件的基本保证那在向写入消息的时候怎么保证消息不丢失呢其实上面的写入流程图中有描述出来那就是通过应答机制在生产者向队列写入数据的时候可以设置参数来确定是否确认接收到数据这个参数可设置的值为代表往集群发送数据不需要等到集群的返回不确保消息发送成功安全性最低但是效率最高代表往集群发送数据只要应答就可以发送下一条只确保发送成功代表往集群发送数据需要所有的都完成从的同步才会发送下一条确保发送成功和所有的副本都完成备份安全性最高但是效率最低最后要注意的是如果往不存在的写数据能不能写入成功呢会自动创建分区和副本的数量根据默认配置都是消费者消费消息存储在文件后消费者就可以进行消费了在讲消息队列通信的两种模式的时候讲到过点对点模式和发布订阅模式采用的是发布订阅模式消费者主动的去集群拉取消息与相同的是消费者在拉取消息的时候也是找去拉取多个消费者可以组成一个消费者组每个消费者组都有一个组同一个消费组者的消费者可以消费同一下不同分区的数据但是不会组内多个消费者消费同一分区的数据如下图高效传输们在的数据进出传输上非常谨慎之前我们已经展示过生产者可以在一次发送请求中提交一组消息尽管最终的消费者是一次迭代一条消息但在底层每次消费者的拉取请求实际上也会获取多条消息直到达到某个大小限制通常是数百我们做的另一个非常规选择是避免在层显式地将消息缓存到内存中相反我们依赖底层文件系统的页缓存这样做的主要好处是避免了双重缓冲消息只会缓存在页缓存中一般的消息队列可能会在进程中缓存这还有一个额外的好处即使进程重启缓存依然是热的页缓存是操控的只要机器不重启只重启实例页缓存依然存在由于完全不在进程中缓存消息它在垃圾回收内存方面的开销非常小从而使基于虚拟机的语言中实现高效运行成为可能如果在堆里缓存大量消息那么这些对象要由管理最后因为生产者和消费者都是顺序访问段文件并且消费者通常只比生产者落后很少一部分所以操作系统的常见缓存机制非常有效特别是写直通缓存和预读机制我们发现生产和消费的性能都能与数据规模保持线性增长甚至能处理多的数据写入是顺序写日志文件消费者拉取数据时也是按顺序读取操作系统的页缓存对顺序有两大优化写直通缓存写数据先放缓存批量刷盘预读读数据时会提前把后面的数据页读进缓存因为生产消费几乎是紧密跟随的缓存的命中率极高性能非常好此外我们还对消费者的网络访问进行了优化是一个多订阅者系统一条消息可能会被不同的消费者应用多次消费通常将本地文件中的字节发送到远程的步骤如下从存储介质读取数据到操作系统的页缓存将页缓存的数据复制到应用缓冲区将应用缓冲区复制到另一个内核缓冲区将内核缓冲区的数据发送到这个过程涉及次数据拷贝和次系统调用在和其他系统上存在一个它可以直接将文件通道中的字节传输到通道这通常能避免第和步引入的次拷贝和次系统调用利用高效地将日志段文件中的字节从传输给消费者注这是零拷贝技术用于操作接口或者接口无论如何都会进入内核态而可以跳过用户态因此在内核态之间的数据传输可以避免用户态的转换无状态与大多数其他消息系统不同在中消费者消费到什么位置的信息并不是由维护的而是由消费者自己维护这种设计减少了的复杂性和开销但这也带来了删除消息的难题因为并不知道所有订阅者是否都消费了该消息用一种简单的基于时间的作为保留策略来解决这个问题如果一条消息在中保存超过一定时间通常是天就会被自动删除这个方案在实践中效果很好大多数消费者包括离线消费者都会按日按小时或实时完成消费而且由于的性能不会随着数据量增大而下降使得长时间保留成为可行的这种设计还有一个重要的副作用消费者可以有意回退到旧的偏移量重新消费数据这虽然违反了队列的一般契约但对很多消费者来说却是必不可少的功能举例来说当消费者应用逻辑出错时修复错误后可以重新回放某些消息这对将数据加载到数据仓库或系统的流程尤其重要再比如消费的数据可能只是定期如批量刷新到持久存储例如全文索引器如果消费者在刷新前崩溃未刷新的数据就会丢失在这种情况下消费者可以记录下未刷新消息的最小并在重启后从该重新消费需要注意的是相比推模式在拉模式下支持消费者回退要容易得多注只存储消息不关心谁消费过是存储和分发消息的系统不记录每个消费者的消费进度好处简化设计高性能不需要频繁更新元数据消费者可以灵活管理消费策略手动自动回溯消费者维护早期及之前存储在中消费者在消费消息后定期提交现在可以存储在内部的特殊消费者拉取提交仅做存储和分发消费者可以自由回溯或跳过因为消费者维护它可以回退重复消费历史消息跳过跳过消息分区协调现在我们描述生产者和消费者在分布式环境下的行为每个生产者可以将消息发布到随机选择的分区或者通过分区键和分区函数语义地决定分区我们将重点放在消费者与的交互上有消费者组的概念每个消费者组由一个或多个消费者组成共同消费一组订阅的主题也就是说每条消息只会被组内的一个消费者接收而不同的消费者组则会彼此独立地消费完整的订阅消息集组与组之间不需要协调组内的消费者可以运行在不同的进程或不同的机器上我们的目标是将中存储的消息尽可能平均地分配给消费者同时避免过多的协调开销我们的第一个决定是将主题中的分区作为最小的并行单元这意味着在任何时刻每个分区的所有消息只会被组内的某一个消费者消费如果允许多个消费者同时消费一个分区它们就必须协调谁消费哪些消息从而引入锁和状态维护的额外开销相比之下在我们的设计中消费者进程只需要在负载重新分配时协调而这是不频繁发生的为了让负载真正均衡我们要求一个主题的分区数远多于每个组内的消费者数通过对主题进行过度分区我们可以很容易做到这一点我们的第二个决定是不设置中心化的节点而是让消费者以去中心化的方式自行协调增加一个节点会使系统更复杂还需要考虑故障问题为实现协调我们使用了一个高可用的一致性服务提供一个非常简单类似文件系统的可以创建路径设置路径的值读取路径的值删除路径列出子路径除此之外它还能做一些有趣的事情可以在路径上注册当路径的值或子路径发生变化时会收到通知路径可以创建为临时的而不是持久的这意味着如果创建它的客户端消失该路径会被自动删除会将数据复制到多个服务器使得数据高度可靠和可用使用来完成以下任务监测和消费者的加入与移除当上述事件发生时触发每个消费者的重新分配流程维护消费关系并记录每个分区的消费偏移量具体来说当每个或消费者启动时它会把自身信息存储在的或注册表中注册表包含的主机名端口以及其存储的主题和分区集合注册表包含消费者所属的消费者组以及它订阅的主题集合每个消费者组在中还有一个分区所有权注册表和一个偏移量注册表所有权注册表为每个订阅分区创建一个路径路径的值为当前正在消费该分区的消费者我们称该消费者拥有该分区偏移量注册表为每个订阅分区存储最近消费过的消息的在中注册表注册表和所有权注册表的路径是临时的而偏移量注册表是持久的因此如果一个故障其上的所有分区会自动从注册表中移除如果一个消费者故障它会丢失在注册表中的记录以及它在所有权注册表中拥有的所有分区每个消费者都会在注册表和注册表上注册当集合或消费者组发生变化时会收到通知每个消费者组都有自己的注册表内部主题彼此独立一个组的消费进度不会影响另一个组在消费者初次启动时或者通过收到变化的通知时消费者会发起一次重新分配流程以确定它应该消费的新分区子集该流程在算法中描述消费者通过读取和注册表先计算出每个订阅主题的可用分区集合以及订阅的消费者集合然后将分区成份并确定性地选择其中一份作为自己的分区对于它选择的每个分区消费者会在所有权注册表中写入自己作为该分区的新最后消费者启动线程从注册表中记录的偏移量开始拉取数据当消息被消费时消费者会定期更新该分区最新的消费当组内有多个消费者时它们都会收到或消费者变化的通知但这些通知到达的时间可能略有不同因此可能会出现某个消费者试图获取另一个消费者仍在拥有的分区的情况这时第一个消费者会简单地释放自己当前拥有的所有分区稍等一会儿后重新尝试实践中流程通常在几次重试后就能稳定下来当一个新的消费者组被创建时偏移量注册表中是没有任何的在这种情况下消费者会从每个订阅分区上可用的最小或最大开始消费具体取决于配置通过我们在上提供的来实现分发保障一般来说只保证至少一次的消息投递精确一次投递通常需要使用两阶段提交对于我们的应用场景并不必要大多数情况下每条消息都会被准确地投递一次到每个消费者组然而如果某个消费者进程在没有干净关闭的情况下崩溃接管这些分区的其他消费者可能会收到一些重复消息这些消息位于最后一次成功提交到的偏移量之后如果应用程序对重复消息敏感就必须自行实现去重逻辑可以使用我们返回给消费者的偏移量或者利用消息中的某个唯一键这通常比使用两阶段提交更具成本效益保证来自同一分区的消息会按顺序投递给消费者但对于来自不同分区的消息不保证顺序注如果一个上的消息发给后没有收到和实际上并不知道这个消息是否成功被消费了因此会尝试重复通知拉取消息这时候就可能出现重复消费的问题因此消费者需要自己保证去重使用消息唯一或缓存幂等处理业务处理可重复执行不会影响结果为了避免日志损坏会为每条消息在日志中存储校验值如果出现任何错误会运行恢复流程删除那些不一致的消息在消息级别保存还可以让我们在消息被生产或消费后检查网络传输错误如果某个崩溃其上存储但尚未被消费的消息将变得不可用如果该的存储系统永久损坏任何未消费的消息将永久丢失未来计划增加内置副本机制将每条消息冗余存储到多个上从而提高可靠性这一个特性在上已经实现了性能测试测试我们将所有系统的配置为异步刷新消息到持久化存储每个系统运行一个发布总共万条消息每条字节配置为批量发送批大小为和和没有方便的批量方式我们假设其批大小为结果如图所示轴表示随时间发送到的数据量轴表示生产者吞吐量条秒平均而言批量大小为时可达条秒批量大小为时可达条秒这比高几个数量级比至少高两倍性能更高的原因包括当前不等待确认尽可能快速发送消息这显著提高了吞吐量批量为时单个几乎饱和了生产者与之间的链路这在日志聚合场景中是合理优化因为数据必须异步发送以避免对实时流量产生延迟未确认时无法保证每条消息都被接收但对于大多数日志数据可以以较小的消息丢失换取吞吐量未来我们计划针对关键数据解决持久化问题的存储格式更高效平均每条消息开销为字节而为字节为存储相同万条消息多消耗了约空间原因包括消息头开销以及维护索引结构的成本最繁忙的线程大部分时间花在访问维护消息元数据和状态批量发送显著提高吞吐量通过摊薄开销批量大小为条时吞吐量几乎提高一个数量级测试第二个实验测试消费者性能所有系统使用单个消费者获取总共万条消息配置每次拉取大致相同数据量最多条或约和消费者设置为自动确认模式由于所有消息都能放入内存系统都从底层文件系统的页面缓存或内存缓冲区提供数据结果如图所示平均而言消费条秒是和的倍以上原因包括存储格式更高效传输的数据量更少和的需要维护每条消息的投递状态的线程在测试中忙于将页面写入磁盘而没有磁盘写操作使用降低了传输开销的缺陷跨分区无法保证全局顺序问题只保证同一分区内顺序不同分区的消息顺序无法保证示例发送购物到结算到消费者可能先消费再消费导致业务逻辑错乱原因分区独立存储并行处理以提高吞吐量系统设计时应该重点考虑跨分区可能存在的全局顺序问题解决方案同消息走同分区通过例如用户保证相关消息落在同一分区应用层顺序控制消费端使用缓存序号等待机制保证业务顺序事务消息使用事务发送多条消息保证原子提交但跨分区顺序仍需应用层处理没有内置死信队列问题消费者处理失败的消息不会自动移入死信队列需要自己处理原因的设计哲学是存储分发消费逻辑由应用负责解决方案应用层实现消费失败的消息写入专门例如支持可以自动把处理失败的消息写入构建多层重试最终失败写入控制消费顺序和延迟至少一次投递可能重复消费问题如果消费者或处理失败会重新发送消息可能重复消费原因依赖提交而不是解决方案幂等消费消费端确保重复处理不会影响结果去重逻辑使用消息唯一或做去重事务消息支持保证事务性消费消息延迟感知受限是拉取模型消费者拉取消息频率影响延迟解决方案调整消费者拉取批次大小和轮询间隔高延迟敏感场景可以用模式或做实时处理单分区性能受限问题一个分区只能由一个消费者消费单分区吞吐有限解决方案采用对热点分区进行平衡注实际上一个对应一个不应该采用多个并行消费一个这可能导致潜在的单分区顺序问题存储依赖磁盘已解决磁盘损坏未消费消息可能丢失解决方案多副本机制生产者配置确保消息写入所有副本重复生产已解决在之前如果生产者未能收到指示消息已提交的响应它别无选择只能重新发送消息这提供了至少一次传递语义因为如果原始请求实际上已成功则在重新发送期间消息可能会再次写入日志从开始生产者还支持幂等传递选项保证重新发送不会导致日志中出现重复条目为了实现这一点代理为每个生产者分配一个并使用生产者随每条消息发送的序列号来删除重复的消息同样从开始生产者支持使用类似事务的语义将消息发送到多个主题分区的能力即要么所有消息都成功写入要么没有一条消息成功写入未来的计划原论文均已实现内置消息复制计划在多个之间增加消息的内置复制以在不可恢复的机器故障情况下保证数据持久性和可用性希望支持异步和同步复制模型让应用在生产者延迟和保证强度之间做权衡应用可以根据对持久性可用性和吞吐量的需求选择合适的冗余级别流处理能力在中增加流处理功能实时应用在获取消息后通常会执行类似窗口统计或者与二级存储或其他流的消息做的操作在最低层通过在发布时按对消息进行语义分区保证所有具有相同的消息进入同一分区从而到达同一个消费者进程这为在消费者集群上处理分布式流奠定了基础在此基础上我们认为提供一套流处理工具库如各种窗口函数或技术对应用非常有帮助上面的计划在之后已经实现分别为副本机制流和表的转换可以实现使用来查找指定的消息',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-01-30 16:31:58',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://npm.elemecdn.com/anzhiyu-blog-static@1.0.4/img/avatar.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">Hexo</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> Newest Comments</span></div><div class="aside-list"><span>loading...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Java/" style="font-size: 1.05rem;">Java<sup>1</sup></a><a href="/tags/JavaScript/" style="font-size: 1.05rem;">JavaScript<sup>1</sup></a><a href="/tags/React/" style="font-size: 1.05rem;">React<sup>1</sup></a><a href="/tags/java/" style="font-size: 1.05rem;">java<sup>2</sup></a><a href="/tags/leetcode/" style="font-size: 1.05rem;">leetcode<sup>5</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 1.05rem;">分布式<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 1.05rem;">数据库<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%BC%E5%90%88/" style="font-size: 1.05rem;">数据库综合<sup>1</sup></a><a href="/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" style="font-size: 1.05rem;">最佳实践<sup>1</sup></a><a href="/tags/%E7%86%94%E6%96%AD/" style="font-size: 1.05rem;">熔断<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" style="font-size: 1.05rem;">网络安全<sup>1</sup></a><a href="/tags/%E9%99%90%E6%B5%81/" style="font-size: 1.05rem;">限流<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2026/01/"><span class="card-archive-list-date">January 2026</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">12</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/12/"><span class="card-archive-list-date">December 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/09/"><span class="card-archive-list-date">September 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">August 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">28</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/" itemprop="url">kafka</a><i class="anzhiyufont anzhiyu-icon-angle-right post-meta-separator"></i><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/kafka/java/" itemprop="url">java</a></span><span class="article-meta tags"></span></div></div><h1 class="post-title" itemprop="name headline">kafka</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-08-11T17:55:16.000Z" title="Created 2025-08-12 01:55:16">2025-08-12</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2026-01-30T08:31:58.576Z" title="Updated 2026-01-30 16:31:58">2026-01-30</time></span></div><div class="meta-secondline"><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为长沙"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>长沙</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src=""></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/"><header><a class="post-meta-categories" href="/categories/kafka/" itemprop="url">kafka</a><a class="post-meta-categories" href="/categories/kafka/java/" itemprop="url">java</a><h1 id="CrawlerTitle" itemprop="name headline">kafka</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">John Doe</span><time itemprop="dateCreated datePublished" datetime="2025-08-11T17:55:16.000Z" title="Created 2025-08-12 01:55:16">2025-08-12</time><time itemprop="dateCreated datePublished" datetime="2026-01-30T08:31:58.576Z" title="Updated 2026-01-30 16:31:58">2026-01-30</time></header><h1 id="初步概念"><a href="#初步概念" class="headerlink" title="初步概念"></a>初步概念</h1><p>Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调<a href="%E5%9C%A84.0%E5%90%8E%E5%AE%8C%E5%85%A8%E7%A7%BB%E9%99%A4%E5%AF%B9ZK%E7%9A%84%E6%94%AF%E6%8C%81%EF%BC%8C%E9%BB%98%E8%AE%A4KRaft%E4%BD%9C%E4%B8%BA%E5%85%83%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%90%86%E5%8D%8F%E8%AE%AE%E3%80%82%E2%80%98">^1</a>的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm&#x2F;Spark流式处理引擎，web&#x2F;nginx日志、访问日志，消息服务等等 </p>
<p>从早期的论文Kafka: a Distributed Messaging System for Log Processing可以看出，kafka最初是设计用于处理大量数据日志的。</p>
<h2 id="消息订阅模式"><a href="#消息订阅模式" class="headerlink" title="消息订阅模式"></a>消息订阅模式</h2><h3 id="1-点对点模式（Point-to-Point-Queue-模式）"><a href="#1-点对点模式（Point-to-Point-Queue-模式）" class="headerlink" title="1. 点对点模式（Point-to-Point, Queue 模式）"></a>1. <strong>点对点模式（Point-to-Point, Queue 模式）</strong></h3><ul>
<li><p><strong>特点</strong>：一个消息只能被一个消费者接收。</p>
</li>
<li><p>生产者把消息发送到队列里，多个消费者竞争消费，但每条消息只会被其中一个消费掉。</p>
</li>
<li><p><strong>应用场景</strong>：任务分发、工作队列。</p>
</li>
<li><p><strong>例子</strong>（JMS Queue &#x2F; RabbitMQ Queue）：</p>
</li>
<li><pre><code>// 假设用 JMS
Queue queue = session.createQueue(&quot;order-queue&quot;);
MessageConsumer consumer = session.createConsumer(queue);

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 2. **发布-订阅模式（Pub/Sub）**</span><br><span class="line"></span><br><span class="line">- **特点**：消息会广播给所有订阅者。</span><br><span class="line"></span><br><span class="line">- 生产者发消息到 Topic，所有订阅该 Topic 的消费者都能收到。</span><br><span class="line"></span><br><span class="line">- **应用场景**：新闻推送、通知广播、多服务监听。</span><br><span class="line"></span><br><span class="line">- **例子**（JMS Topic / Kafka Topic）：</span><br><span class="line"></span><br><span class="line">- ```</span><br><span class="line">  Topic topic = session.createTopic(&quot;news-topic&quot;);</span><br><span class="line">  MessageConsumer consumer = session.createConsumer(topic);</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
<h2 id="设计架构"><a href="#设计架构" class="headerlink" title="设计架构"></a>设计架构</h2><p>kafka的数据流的特殊格式为<code>topic</code>主题，一个<code>consumer</code>消费者从<code>broker</code>（经纪人，在这里是kafka的实例）可以订阅一个或者多个<code>topic</code>。</p>
<p>要发布一个消息，生产者可以使用Byte类型，意味着由生产者决定如何序列化，并且发布到指定的topic上。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">producer = new Producer(...);</span><br><span class="line">message = new Message(“test message str”.getBytes());</span><br><span class="line">set = new MessageSet(message);</span><br><span class="line">producer.send(“topic1”, set);</span><br></pre></td></tr></table></figure>

<p>要订阅一个主题（topic），消费者首先会为该主题创建一个或多个消息流（message stream）。<br> 发布到该主题的消息会被均匀地分配到这些子流中。每个消息流都提供了一个迭代器接口，用于遍历源源不断产生的消息。消费者随后通过遍历流中的每一条消息来处理其载荷（payload）。与传统迭代器不同，消息流迭代器永远不会终止。<br> 如果当前没有新的消息可供消费，迭代器会阻塞，直到有新的消息发布到该主题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">streams[] = Consumer.createMessageStreams(“topic1”, 1)</span><br><span class="line">for (message : streams[0]) &#123;</span><br><span class="line">bytes = message.payload();</span><br><span class="line">// do something with the bytes</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930152156925.png" alt="image-20250930142805175"></p>
<p>Producer：Producer即生产者，消息的产生者，是消息的入口。</p>
<p>Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等</p>
<p>Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。</p>
<p>Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！</p>
<p>Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。</p>
<p>Message：每一条发送的消息主体。Consumer：消费者，即消息的消费方，是消息的出口。</p>
<p>Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！</p>
<p>Zookeeper：kafka集群依赖zookeeper来保存集群的的元信息，来保证系统的可用性。</p>
<h2 id="存储布局"><a href="#存储布局" class="headerlink" title="存储布局"></a>存储布局</h2><p>Kafka 具有非常简单的存储布局。一个主题（topic）的每个分区（partition）对应一个逻辑日志（logical log）。在物理层面上，一个日志被实现为一组大小大致相同的段文件（segment file）（例如，1GB）。</p>
<p>每当生产者向某个分区发布消息时，broker 只需将该消息追加写入最后一个段文件。<br> 为了获得更好的性能，段文件并不是每写一次就刷盘，而是在 <strong>发布了可配置数量的消息</strong> 或者 <strong>经过了一定时间</strong> 后才会刷盘到磁盘。只有当消息被刷盘后，它才会对消费者可见。</p>
<p>与典型的消息系统不同，Kafka 中存储的消息没有显式的消息 ID。相反，每条消息通过其在日志中的逻辑偏移量（offset）来寻址。这样避免了维护额外的、需要频繁随机访问的索引结构（将消息 ID 映射到消息实际位置）的开销。需要注意的是：我们的消息 ID 是递增的，但不是连续的。要计算下一条消息的 ID，我们需要将当前消息的长度加到它的 ID 上。从此以后，我们会将消息 ID 和偏移量（offset）交替使用。</p>
<p>消费者始终顺序地消费某个分区中的消息。如果消费者确认（acknowledge）了某个消息的偏移量，就意味着它已经收到了该分区中该偏移量之前的所有消息。</p>
<p>在底层，消费者会向 broker 发送异步的拉取请求（pull request），以便提前准备好一批数据供应用消费。每个拉取请求包含：</p>
<ul>
<li>开始消费的消息偏移量</li>
<li>可接受的最大字节数</li>
</ul>
<p>每个 broker 在内存中维护一个已排序的偏移量列表，包括每个段文件中第一条消息的偏移量。broker 会通过查找该偏移量列表，定位到所请求的消息所在的段文件，并将数据返回给消费者。</p>
<p>当消费者收到一条消息后，会计算出下一条消息的偏移量，并在下一次拉取请求中使用它。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930152154813.png" alt="image-20250930144654175" style="zoom:50%;" />

<h3 id="Partition结构"><a href="#Partition结构" class="headerlink" title="Partition结构"></a>Partition结构</h3><p>每个topic可以划分为一个或者多个Partition，在服务器上的表现为一段连续的磁盘存储，每个Partition下有多个Segment文件，每个Segment包含.index文件，.log文件，.timeindex文件。其中log文件为具体的消息，.index和.timeindex为索引。</p>
<p><strong>偏移量索引（Offset Index）</strong></p>
<ul>
<li>每个 Partition 都有一个 <code>.index</code> 文件。</li>
<li>它是一个稀疏索引（sparse index），记录 <strong>逻辑 offset → 物理文件位置（position）</strong> 的映射。</li>
<li>Kafka 并不会为每条消息建立索引，而是隔固定字节数（默认约 4KB）写入一条索引。</li>
<li>查找时：Kafka 先在索引文件里二分查找，找到最接近的 offset 对应的物理位置，再顺序扫描到目标消息。</li>
</ul>
<p><strong>时间戳索引（Time Index）</strong></p>
<ul>
<li>每个 Partition 还有一个 <code>.timeindex</code> 文件。</li>
<li>用于记录 <strong>时间戳 → 物理文件位置</strong> 的映射。</li>
<li>查找消息时，如果用户按时间查找，Kafka 会在这个文件里二分查找，定位大致位置，然后再回到 <code>.index</code> 文件+日志文件扫描。</li>
</ul>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930152149236.png" alt="image-20250930145151958" style="zoom:50%;" />

<p>.index是辅助查询的稀疏索引，而.log文件是真正的记录，要查找offset，需要经过稀疏索引的二次跳转。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930152152247.png" alt="image-20250930145739750"></p>
<ol>
<li><p>例如查找offset为368801的物理位置，先找到offset的368801message所在的segment文件（利用二分法查找），这里找到的就是在第二个segment文件。</p>
</li>
<li><p>打开找到的segment中的.index文件（也就是368796.index文件，该文件起始偏移量为368796+1，我们要查找的offset为368801的message在该index内的偏移量为368796+5&#x3D;368801，所以这里要查找的相对offset为5）。由于该文件采用的是稀疏索引的方式存储着相对offset及对应message物理偏移量的关系，所以直接找相对offset为5的索引找不到，这里同样利用二分法查找相对offset小于或者等于指定的相对offset的索引条目中最大的那个相对offset，所以找到的是相对offset为4的这个索引。</p>
</li>
<li><p>根据找到的相对offset为4的索引确定message存储的物理偏移位置为256。打开数据文件，从位置为256的那个地方开始顺序扫描直到找到offset为368801的那条Message。这套机制是建立在offset为有序的基础上，利用segment+有序offset+稀疏索引+二分查找+顺序查找等多种手段来高效的查找数据！</p>
</li>
</ol>
<h3 id="message结构"><a href="#message结构" class="headerlink" title="message结构"></a>message结构</h3><p>在 Kafka 中，每条消息被封装成一个 <strong>Message</strong>，存储在 <strong>Partition 的 Log</strong> 中，主要包含以下部分：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Offset</strong></td>
<td>分区内的唯一序号，标识消息在分区中的位置。消费者依赖它来跟踪消费进度。</td>
</tr>
<tr>
<td><strong>Key</strong></td>
<td>可选，用于分区路由（Producer 根据 Key 选择 Partition）。</td>
</tr>
<tr>
<td><strong>Value</strong></td>
<td>消息的实际内容，即业务数据。</td>
</tr>
<tr>
<td><strong>Timestamp</strong></td>
<td>消息的时间戳（创建时间或日志时间），可选用于时间索引。</td>
</tr>
<tr>
<td><strong>Headers</strong></td>
<td>可选的元数据，用于存储附加信息（比如 traceId、消息类型等）。</td>
</tr>
<tr>
<td><strong>CRC</strong></td>
<td>校验码，用于检测消息在存储或传输过程中的损坏。</td>
</tr>
</tbody></table>
<blockquote>
<p>注意：Kafka 0.10+ 引入了 <strong>批量消息（MessageBatch&#x2F;MessageSet）</strong>，为了减少磁盘 I&#x2F;O，会把多条消息打包存储在同一段日志中。</p>
</blockquote>
<h3 id="存储策略"><a href="#存储策略" class="headerlink" title="存储策略"></a>存储策略</h3><p>Kafka 支持两种策略删除旧消息：</p>
<ol>
<li><strong>按时间（log.retention.ms）</strong>：保留最近 N 毫秒的消息，超过则删除。默认为7天。</li>
<li><strong>按大小（log.retention.bytes）</strong>：保留日志总大小，超过则删除最老的 segment。</li>
<li><strong>压缩策略（log.cleanup.policy&#x3D;compact）</strong>：<ul>
<li>对于有 Key 的消息，同一个 Key 只保留最新的消息。</li>
<li>适合状态消息、去重场景</li>
</ul>
</li>
</ol>
<h3 id="定位消息"><a href="#定位消息" class="headerlink" title="定位消息"></a>定位消息</h3><p>假设要读取 offset &#x3D; <code>O</code> 的消息：</p>
<ol>
<li><strong>定位 Segment</strong><ul>
<li>Kafka 用 partition 的 segment 列表 + base offset 找到包含 offset <code>O</code> 的 segment。</li>
<li>因为 segment 按 base offset 排序 → 可以用 <strong>二分查找</strong> → 时间复杂度 <code>O(log S)</code>，S &#x3D; segment 数量。</li>
</ul>
</li>
<li><strong>查找 offset 在 segment 内的位置</strong><ul>
<li>通过 offset 索引（稀疏索引），先定位到最接近的索引 entry → 索引查找可视作 <strong>二分查找</strong> → 时间复杂度 <code>O(log N_idx)</code>，N_idx &#x3D; segment 内索引条目数。</li>
<li>然后从索引位置向前或向后扫描若干条消息，找到确切 offset → 最多扫描 <strong>N_sparse</strong> 条消息（稀疏索引步长，通常 4KB 对应 ~1000 条消息），这个可以视为 <strong>常数级操作</strong>。</li>
</ul>
</li>
<li><strong>读取消息</strong><ul>
<li>消息在文件中是顺序存储的，找到位置后直接从页缓存或磁盘读取 → 顺序 I&#x2F;O，非常快。</li>
</ul>
</li>
</ol>
<h3 id="综合时间复杂度"><a href="#综合时间复杂度" class="headerlink" title="综合时间复杂度"></a>综合时间复杂度</h3><ul>
<li><strong>查找 segment</strong>：<code>O(log S)</code></li>
<li><strong>查找 segment 内 offset</strong>：<code>O(log N_idx) </code></li>
<li>总复杂度： 接近 <code>O(log S + log N_idx)</code>。</li>
<li><strong>读取消息</strong>：顺序 I&#x2F;O，通常视为 <code>O(1)</code>（在页缓存命中情况下）</li>
</ul>
<blockquote>
<p>实际上，S（segment 数量）和 N_idx（segment 内索引条目数）都非常小，N_sparse 通常 1k 条左右，所以<strong>查找非常快</strong>。</p>
</blockquote>
<h3 id="数据访问流程（存储角度）"><a href="#数据访问流程（存储角度）" class="headerlink" title="数据访问流程（存储角度）"></a><strong>数据访问流程（存储角度）</strong></h3><ol>
<li>Producer 写消息 → append 到分区 segment → 写入页缓存（顺序写）。</li>
<li>Broker 定期刷新页缓存到磁盘（fsync），或者由操作系统异步刷盘。</li>
<li>Consumer 拉消息 → 从页缓存读取 → 消费后提交 offset。</li>
</ol>
<h2 id="生产者生产"><a href="#生产者生产" class="headerlink" title="生产者生产"></a>生产者生产</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930165926674.png" alt="image-20250930165926452"></p>
<p>消息写入leader后，follower是主动的去leader进行同步的！producer采用push模式将数据发布到broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的！写入示意图如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930170011532.png" alt="image-20250930170011478"></p>
<p>分区的主要目的是：</p>
<ol>
<li>方便扩展：因为一个topic可以有多个partition，所以我们可以通过扩展机器去轻松的应对日益增长的数据量。</li>
<li>提高并发：以partition为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。熟悉负载均衡的朋友应该知道，当我们向某个服务器发送请求的时候，服务端可能会对请求做一个负载，将流量分发到不同的服务器，那在kafka中，如果某个topic有多个partition，producer又怎么知道该将数据发往哪个partition呢？</li>
</ol>
<p>kafka中有几个原则：partition在写入的时候可以指定需要写入的partition，如果有指定，则写入对应的partition。如果没有指定partition，但是设置了数据的key，则会根据key的值hash出一个partition。如果既没指定partition，又没有设置key，则会轮询选出一个partition。保证消息不丢失是一个消息队列中间件的基本保证，那producer在向kafka写入消息的时候，怎么保证消息不丢失呢？</p>
<p>其实上面的写入流程图中有描述出来，那就是通过ACK应答机制！在生产者向队列写入数据的时候可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为0、1、all。</p>
<p>0代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。</p>
<p>1代表producer往集群发送数据只要leader应答就可以发送下一条，只确保leader发送成功。</p>
<p>all代表producer往集群发送数据需要所有的follower都完成从leader的同步才会发送下一条，确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。</p>
<p>最后要注意的是，如果往不存在的topic写数据，能不能写入成功呢？kafka会自动创建topic，分区和副本的数量根据默认配置都是1。</p>
<h2 id="消费者消费"><a href="#消费者消费" class="headerlink" title="消费者消费"></a>消费者消费</h2><p>消息存储在log文件后，消费者就可以进行消费了。在讲消息队列通信的两种模式的时候讲到过点对点模式和发布订阅模式。Kafka采用的是发布订阅模式，消费者主动的去kafka集群拉取消息，与producer相同的是，消费者在拉取消息的时候也是找leader去拉取。</p>
<p>多个消费者可以组成一个消费者组（consumer group），每个消费者组都有一个组id！同一个消费组者的消费者可以消费同一topic下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！如下图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930171713049.png" alt="image-20250930171712978"></p>
<h2 id="高效传输"><a href="#高效传输" class="headerlink" title="高效传输"></a>高效传输</h2><p>们在 Kafka 的数据进出传输上非常谨慎。之前我们已经展示过，生产者可以在一次发送请求中提交一组消息。尽管最终的消费者 API 是一次迭代一条消息，但在底层，每次消费者的拉取请求实际上也会获取多条消息，直到达到某个大小限制，通常是数百 KB。</p>
<p>我们做的另一个非常规选择是：避免在 Kafka 层显式地将消息缓存到内存中。相反，我们依赖底层文件系统的页缓存（page cache）。这样做的主要好处是避免了“双重缓冲”——消息只会缓存在页缓存中。（一般的消息队列可能会在进程中缓存）</p>
<p>这还有一个额外的好处：即使 broker 进程重启，缓存依然是“热的”。（页缓存是OS操控的，只要机器不重启，只重启实例，页缓存依然存在）</p>
<p>由于 Kafka 完全不在进程中缓存消息，它在垃圾回收内存方面的开销非常小，从而使基于虚拟机（VM）的语言中实现高效运行成为可能。（如果 Kafka 在 JVM 堆里缓存大量消息，那么这些对象要由 GC 管理。）</p>
<p>最后，因为生产者和消费者都是顺序访问段文件（segment files），并且消费者通常只比生产者落后很少一部分，所以操作系统的常见缓存机制非常有效（特别是写直通缓存和预读机制）。我们发现生产和消费的性能都能与数据规模保持线性增长，甚至能处理多 TB 的数据。</p>
<p>Kafka 写入是 <strong>顺序写日志文件</strong>。</p>
<p>消费者拉取数据时，也是按顺序读取。</p>
<p>操作系统的页缓存对顺序 I&#x2F;O 有两大优化：</p>
<ul>
<li><strong>写直通缓存（write-back caching）</strong>：写数据先放缓存，批量刷盘。</li>
<li><strong>预读（read-ahead）</strong>：读数据时，OS 会提前把后面的数据页读进缓存。</li>
</ul>
<p>因为生产&#x2F;消费几乎是紧密跟随的，OS 缓存的命中率极高 → <strong>性能非常好</strong>。</p>
<p>此外，我们还对消费者的网络访问进行了优化。Kafka 是一个多订阅者系统，一条消息可能会被不同的消费者应用多次消费。通常，将本地文件中的字节发送到远程 socket 的步骤如下：</p>
<ol>
<li>从存储介质读取数据到操作系统的页缓存；</li>
<li>将页缓存的数据复制到应用缓冲区；</li>
<li>将应用缓冲区复制到另一个内核缓冲区；</li>
<li>将内核缓冲区的数据发送到 socket。</li>
</ol>
<p>这个过程涉及 <strong>4 次数据拷贝和 2 次系统调用</strong>。在 Linux 和其他 Unix 系统上，存在一个 <strong>sendfile API</strong>，它可以直接将文件通道中的字节传输到 socket 通道。这通常能避免第 (2) 和 (3) 步引入的 <strong>2 次拷贝和 1 次系统调用</strong>。Kafka 利用 sendfile API 高效地将日志段文件中的字节从 broker 传输给消费者。</p>
<blockquote>
<p>注：这是零拷贝技术，用于操作IO接口或者Socket接口无论如何都会进入内核态，而可以跳过用户态，因此在内核态之间的数据传输可以避免用户态的转换。</p>
</blockquote>
<h2 id="无状态-broker"><a href="#无状态-broker" class="headerlink" title="无状态 broker"></a><strong>无状态 broker</strong></h2><p>与大多数其他消息系统不同，在 Kafka 中，消费者消费到什么位置的信息并不是由 broker 维护的，而是由消费者自己维护。这种设计减少了 broker 的复杂性和开销。但这也带来了删除消息的难题，因为 broker 并不知道所有订阅者是否都消费了该消息。Kafka 用一种简单的基于时间的 SLA 作为保留策略来解决这个问题：如果一条消息在 broker 中保存超过一定时间（通常是 7 天），就会被自动删除。这个方案在实践中效果很好。大多数消费者（包括离线消费者）都会按日、按小时或实时完成消费。而且，由于 Kafka 的性能不会随着数据量增大而下降，使得长时间保留成为可行的。</p>
<p>这种设计还有一个重要的副作用：消费者可以有意回退到旧的偏移量（offset）重新消费数据。这虽然违反了队列的一般契约，但对很多消费者来说却是必不可少的功能。举例来说，当消费者应用逻辑出错时，修复错误后可以重新回放某些消息。这对将数据加载到数据仓库或 Hadoop 系统的 ETL 流程尤其重要。再比如，消费的数据可能只是定期（如批量）刷新到持久存储（例如全文索引器）。如果消费者在刷新前崩溃，未刷新的数据就会丢失。在这种情况下，消费者可以记录下未刷新消息的最小 offset，并在重启后从该 offset 重新消费。需要注意的是，相比推模式（push model），在拉模式（pull model）下支持消费者回退要容易得多。</p>
<blockquote>
<p>注：<strong>Broker 只存储消息，不关心谁消费过</strong></p>
<ul>
<li>Broker 是“存储和分发消息的系统”，不记录每个消费者的消费进度</li>
<li>好处：<ul>
<li>简化 Broker 设计</li>
<li>高性能（不需要频繁更新元数据）</li>
<li>消费者可以灵活管理消费策略（手动&#x2F;自动&#x2F;回溯）</li>
</ul>
</li>
</ul>
<p><strong>消费者维护 offset</strong></p>
<ul>
<li>早期 Kafka（0.8.x 及之前）：<ul>
<li>offset 存储在 <strong>Zookeeper</strong> 中</li>
<li>消费者在消费消息后，定期提交 offset</li>
</ul>
</li>
<li>现在 Kafka（0.9+）：<ul>
<li>offset 可以存储在 <strong>Kafka 内部的特殊 topic <code>__consumer_offsets</code></strong></li>
<li>消费者拉取、提交 offset → Kafka 仅做存储和分发</li>
</ul>
</li>
</ul>
<p><strong>消费者可以自由回溯或跳过</strong></p>
<ul>
<li>因为消费者维护 offset，它可以：<ul>
<li>回退 offset → 重复消费历史消息</li>
<li>跳过 offset → 跳过消息</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="分区协调"><a href="#分区协调" class="headerlink" title="分区协调"></a>分区协调</h2><p>现在我们描述生产者和消费者在分布式环境下的行为。每个生产者可以将消息发布到随机选择的分区，或者通过分区键和分区函数语义地决定分区。我们将重点放在消费者与 broker 的交互上。</p>
<p>Kafka 有 <strong>消费者组（consumer groups）</strong> 的概念。每个消费者组由一个或多个消费者组成，共同消费一组订阅的主题。也就是说，每条消息只会被组内的一个消费者接收。而不同的消费者组则会彼此独立地消费完整的订阅消息集，组与组之间不需要协调。组内的消费者可以运行在不同的进程或不同的机器上。我们的目标是：将 broker 中存储的消息尽可能平均地分配给消费者，同时避免过多的协调开销。</p>
<p>我们的第一个决定是：<strong>将主题中的分区作为最小的并行单元</strong>。这意味着在任何时刻，每个分区的所有消息，只会被组内的某一个消费者消费。如果允许多个消费者同时消费一个分区，它们就必须协调谁消费哪些消息，从而引入锁和状态维护的额外开销。相比之下，在我们的设计中，消费者进程只需要在负载重新分配（rebalance）时协调，而这是不频繁发生的。为了让负载真正均衡，我们要求一个主题的分区数远多于每个组内的消费者数。通过对主题进行过度分区（over-partitioning），我们可以很容易做到这一点。</p>
<p>我们的第二个决定是：<strong>不设置中心化的 master 节点</strong>，而是让消费者以去中心化的方式自行协调。增加一个 master 节点会使系统更复杂，还需要考虑 master 故障问题。为实现协调，我们使用了一个高可用的一致性服务 —— <strong>Zookeeper</strong>。</p>
<p>Zookeeper 提供一个非常简单、类似文件系统的 API：可以创建路径、设置路径的值、读取路径的值、删除路径、列出子路径。除此之外，它还能做一些有趣的事情：<br> (a) 可以在路径上注册 <strong>watcher</strong>，当路径的值或子路径发生变化时会收到通知；<br> (b) 路径可以创建为 <strong>临时（ephemeral）</strong> 的（而不是持久的），这意味着如果创建它的客户端消失，该路径会被 Zookeeper 自动删除；<br> (c) Zookeeper 会将数据复制到多个服务器，使得数据高度可靠和可用。</p>
<p>Kafka 使用 Zookeeper 来完成以下任务：</p>
<ol>
<li>监测 broker 和消费者的加入与移除；</li>
<li>当上述事件发生时触发每个消费者的重新分配（rebalance）流程；</li>
<li>维护消费关系，并记录每个分区的消费偏移量（offset）。</li>
</ol>
<p>具体来说，当每个 broker 或消费者启动时，它会把自身信息存储在 Zookeeper 的 broker 或 consumer 注册表中。</p>
<ul>
<li><strong>broker 注册表</strong>：包含 broker 的主机名、端口，以及其存储的主题和分区集合。</li>
<li><strong>consumer 注册表</strong>：包含消费者所属的消费者组，以及它订阅的主题集合。</li>
</ul>
<p>每个消费者组在 Zookeeper 中还有一个 <strong>分区所有权注册表（ownership registry）</strong> 和一个 <strong>偏移量注册表（offset registry）</strong>：</p>
<ul>
<li>所有权注册表：为每个订阅分区创建一个路径，路径的值为当前正在消费该分区的消费者 id（我们称该消费者“拥有”该分区）；</li>
<li>偏移量注册表：为每个订阅分区存储最近消费过的消息的 offset。</li>
</ul>
<p>在 Zookeeper 中，broker 注册表、consumer 注册表和所有权注册表的路径是临时的（ephemeral），而偏移量注册表是持久的（persistent）。因此：</p>
<ul>
<li>如果一个 broker 故障，其上的所有分区会自动从 broker 注册表中移除；</li>
<li>如果一个消费者故障，它会丢失在 consumer 注册表中的记录以及它在所有权注册表中拥有的所有分区。</li>
</ul>
<p>每个消费者都会在 broker 注册表和 consumer 注册表上注册 Zookeeper watcher，当 broker 集合或消费者组发生变化时会收到通知。</p>
<p><strong>每个消费者组都有自己的 offset 注册表</strong>（<code>__consumer_offsets</code> 内部主题），彼此独立。</p>
<p><strong>一个组的消费进度不会影响另一个组</strong>。</p>
<p>在消费者初次启动时，或者通过 watcher 收到 broker&#x2F;consumer 变化的通知时，消费者会发起一次 <strong>重新分配（rebalance）</strong> 流程，以确定它应该消费的新分区子集。该流程在算法 1 中描述：</p>
<ul>
<li>消费者通过 Zookeeper 读取 broker 和 consumer 注册表，先计算出每个订阅主题 T 的可用分区集合 (P_T)，以及订阅 T 的消费者集合 (C_T)；</li>
<li>然后将 P_T 分区成 |C_T| 份，并确定性地选择其中一份作为自己的分区；</li>
<li>对于它选择的每个分区，消费者会在所有权注册表中写入自己作为该分区的新 owner；</li>
<li>最后，消费者启动线程，从 offset 注册表中记录的偏移量开始拉取数据。当消息被消费时，消费者会定期更新该分区最新的消费 offset。</li>
</ul>
<p>当组内有多个消费者时，它们都会收到 broker 或消费者变化的通知。但这些通知到达的时间可能略有不同，因此可能会出现某个消费者试图获取另一个消费者仍在拥有的分区的情况。这时，第一个消费者会简单地释放自己当前拥有的所有分区，稍等一会儿后重新尝试 rebalance。实践中，rebalance 流程通常在几次重试后就能稳定下来。</p>
<p>当一个新的消费者组被创建时，偏移量注册表中是没有任何 offset 的。在这种情况下，消费者会从每个订阅分区上可用的最小或最大 offset 开始消费（具体取决于配置），通过我们在 broker 上提供的 API 来实现。</p>
<h2 id="分发保障"><a href="#分发保障" class="headerlink" title="分发保障"></a>分发保障</h2><p>一般来说，Kafka 只保证 <strong>至少一次（at-least-once）</strong> 的消息投递。<strong>精确一次（exactly-once）</strong> 投递通常需要使用 <strong>两阶段提交（two-phase commits）</strong>，对于我们的应用场景并不必要。大多数情况下，每条消息都会被 <strong>准确地投递一次</strong> 到每个消费者组。然而，如果某个消费者进程在没有干净关闭的情况下崩溃，接管这些分区的其他消费者可能会收到一些重复消息，这些消息位于最后一次成功提交到 Zookeeper 的偏移量之后。如果应用程序对重复消息敏感，就必须自行实现 <strong>去重逻辑</strong>，可以使用我们返回给消费者的偏移量，或者利用消息中的某个唯一键。这通常比使用两阶段提交更具成本效益。</p>
<p>Kafka 保证来自同一分区的消息会 <strong>按顺序投递给消费者</strong>，但对于来自不同分区的消息，<strong>不保证顺序</strong>。</p>
<blockquote>
<p>注：如果一个partition上的消息发给consumer后没有收到ack和offset，kafka实际上并不知道这个消息是否成功被消费了，因此会尝试重复通知consumer拉取消息，这时候就可能出现重复消费的问题。因此消费者需要自己保证：</p>
<p><strong>去重</strong>（使用消息唯一 key 或缓存 offset）；</p>
<p><strong>幂等处理</strong>（业务处理可重复执行不会影响结果）。</p>
</blockquote>
<p>为了避免日志损坏，Kafka 会为每条消息在日志中存储 <strong>CRC 校验值</strong>。如果 Broker 出现任何 I&#x2F;O 错误，Kafka 会运行恢复流程，删除那些 CRC 不一致的消息。在消息级别保存 CRC 还可以让我们在消息被生产或消费后，检查网络传输错误。</p>
<p>如果某个 Broker 崩溃，其上存储但尚未被消费的消息将 <strong>变得不可用</strong>。如果该 Broker 的存储系统永久损坏，任何未消费的消息将 <strong>永久丢失</strong>。</p>
<p>未来，Kafka 计划增加 <strong>内置副本机制</strong>，将每条消息冗余存储到多个 Broker 上，从而提高可靠性。【这一个特性在kafka上已经实现了】</p>
<h2 id="kafka性能测试"><a href="#kafka性能测试" class="headerlink" title="kafka性能测试"></a>kafka性能测试</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/yicizhang00/image_host/main/blog-img/20250930174512309.png" alt="image-20250930174512189"></p>
<h3 id="Producer-测试"><a href="#Producer-测试" class="headerlink" title="Producer 测试"></a>Producer 测试</h3><p>我们将所有系统的 Broker 配置为异步刷新消息到持久化存储。每个系统运行一个 Producer，发布总共 1000 万条消息，每条 200 字节。Kafka Producer 配置为批量发送，批大小为 1 和 50。ActiveMQ 和 RabbitMQ 没有方便的批量方式，我们假设其批大小为 1。结果如图 4 所示：x 轴表示随时间发送到 Broker 的数据量（MB），y 轴表示生产者吞吐量（条&#x2F;秒）。平均而言，Kafka 批量大小为 1 时可达 50,000 条&#x2F;秒，批量大小为 50 时可达 400,000 条&#x2F;秒。这比 ActiveMQ 高几个数量级，比 RabbitMQ 至少高两倍。</p>
<p>Kafka 性能更高的原因包括：</p>
<ol>
<li>Kafka Producer 当前不等待 Broker 确认，尽可能快速发送消息，这显著提高了吞吐量。批量为 50 时，单个 Kafka Producer 几乎饱和了生产者与 Broker 之间的 1Gb 链路。这在日志聚合场景中是合理优化，因为数据必须异步发送以避免对实时流量产生延迟。未确认时无法保证每条消息都被 Broker 接收，但对于大多数日志数据，可以以较小的消息丢失换取吞吐量。未来我们计划针对关键数据解决持久化问题。</li>
<li>Kafka 的存储格式更高效。平均每条消息开销为 9 字节，而 ActiveMQ 为 144 字节。ActiveMQ 为存储相同 1000 万条消息多消耗了约 70% 空间，原因包括 JMS 消息头开销以及维护索引结构的成本。ActiveMQ 最繁忙的线程大部分时间花在访问 B-Tree 维护消息元数据和状态。</li>
<li>批量发送显著提高吞吐量，通过摊薄 RPC 开销。Kafka 批量大小为 50 条时，吞吐量几乎提高一个数量级。</li>
</ol>
<h3 id="Consumer-测试"><a href="#Consumer-测试" class="headerlink" title="Consumer 测试"></a>Consumer 测试</h3><p>第二个实验测试消费者性能。所有系统使用单个消费者，获取总共 1000 万条消息。配置每次拉取大致相同数据量——最多 1000 条或约 200KB。ActiveMQ 和 RabbitMQ 消费者设置为自动确认模式。由于所有消息都能放入内存，系统都从底层文件系统的页面缓存或内存缓冲区提供数据。结果如图 5 所示。</p>
<p>平均而言，Kafka 消费 22,000 条&#x2F;秒，是 ActiveMQ 和 RabbitMQ 的 4 倍以上。原因包括：</p>
<ol>
<li>Kafka 存储格式更高效，传输的数据量更少；</li>
<li>ActiveMQ 和 RabbitMQ 的 Broker 需要维护每条消息的投递状态；</li>
<li>ActiveMQ 的线程在测试中忙于将 KahaDB 页面写入磁盘，而 Kafka Broker 没有磁盘写操作；</li>
<li>Kafka 使用 <code>sendfile</code> API，降低了传输开销。</li>
</ol>
<h2 id="kafka的缺陷"><a href="#kafka的缺陷" class="headerlink" title="kafka的缺陷"></a>kafka的缺陷</h2><h3 id="1-跨分区无法保证全局顺序"><a href="#1-跨分区无法保证全局顺序" class="headerlink" title="1. 跨分区无法保证全局顺序"></a>1. <strong>跨分区无法保证全局顺序</strong></h3><ul>
<li><strong>问题</strong>：Kafka 只保证 <strong>同一分区内顺序</strong>，不同分区的消息顺序无法保证。<ul>
<li>示例：Producer 发送 <code>m1=购物</code> 到 partition1，<code>m2=结算</code> 到 partition2 → 消费者可能先消费 <code>m2</code> 再消费 <code>m1</code>，导致业务逻辑错乱。</li>
</ul>
</li>
<li><strong>原因</strong>：Kafka 分区独立存储、并行处理以提高吞吐量。</li>
<li>系统设计时应该重点考虑跨分区可能存在的全局顺序问题。</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ol>
<li><strong>同 key 消息走同分区</strong><ul>
<li>通过 key（例如用户 ID）保证相关消息落在同一分区。</li>
</ul>
</li>
<li><strong>应用层顺序控制</strong><ul>
<li>消费端使用缓存&#x2F;序号等待机制，保证业务顺序。</li>
</ul>
</li>
<li><strong>事务消息（Kafka 0.11+）</strong><ul>
<li>Producer 使用事务发送多条消息，保证原子提交，但跨分区顺序仍需应用层处理。</li>
</ul>
</li>
</ol>
<h3 id="2-没有内置死信队列（DLQ）"><a href="#2-没有内置死信队列（DLQ）" class="headerlink" title="2. 没有内置死信队列（DLQ）"></a>2. <strong>没有内置死信队列（DLQ）</strong></h3><ul>
<li><strong>问题</strong>：消费者处理失败的消息不会自动移入死信队列，需要自己处理。</li>
<li><strong>原因</strong>：Kafka 的设计哲学是存储+分发，消费逻辑由应用负责。</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ol>
<li><strong>应用层实现 DLQ</strong><ul>
<li>消费失败的消息写入专门 topic（例如 <code>topic.DLQ</code>）。</li>
</ul>
</li>
<li><strong>Kafka Connect &#x2F; Kafka Streams 支持 DLQ</strong><ul>
<li>Connector 可以自动把处理失败的消息写入 DLQ topic。</li>
</ul>
</li>
<li><strong>Retry Topic + DLQ</strong><ul>
<li>构建多层重试 topic → 最终失败写入 DLQ，控制消费顺序和延迟。</li>
</ul>
</li>
</ol>
<h3 id="3-至少一次投递（可能重复消费）"><a href="#3-至少一次投递（可能重复消费）" class="headerlink" title="3. 至少一次投递（可能重复消费）"></a>3. <strong>至少一次投递（可能重复消费）</strong></h3><ul>
<li><strong>问题</strong>：如果消费者 crash 或处理失败，Kafka 会重新发送消息 → 可能重复消费。</li>
<li><strong>原因</strong>：Kafka 依赖 offset 提交，而不是 ACK。</li>
</ul>
<p><strong>解决方案</strong>：</p>
<ol>
<li><strong>幂等消费</strong><ul>
<li>消费端确保重复处理不会影响结果。</li>
</ul>
</li>
<li><strong>去重逻辑</strong><ul>
<li>使用消息唯一 ID 或 offset 做去重。</li>
</ul>
</li>
<li><strong>事务消息</strong><ul>
<li>Kafka Producer&#x2F;Consumer 支持 exactly-once semantics（EOS），保证事务性消费。</li>
</ul>
</li>
</ol>
<h3 id="4-消息延迟感知受限"><a href="#4-消息延迟感知受限" class="headerlink" title="4. 消息延迟感知受限"></a>4. <strong>消息延迟感知受限</strong></h3><ul>
<li>Kafka 是 <strong>拉取（pull）模型</strong>，消费者拉取消息频率影响延迟。</li>
<li><strong>解决方案</strong>：<ul>
<li>调整消费者拉取批次大小和轮询间隔（<code>fetch.min.bytes</code>, <code>fetch.max.wait.ms</code>）。</li>
<li>高延迟敏感场景可以用 <strong>push 模式 MQ 或 Flink&#x2F;Kafka Streams</strong> 做实时处理。</li>
</ul>
</li>
</ul>
<h3 id="5-单分区性能受限"><a href="#5-单分区性能受限" class="headerlink" title="5. 单分区性能受限"></a>5. <strong>单分区性能受限</strong></h3><ul>
<li><strong>问题</strong>：一个分区只能由一个消费者消费 → 单分区吞吐有限。</li>
<li><strong>解决方案</strong>：<ul>
<li>采用key对热点分区进行平衡。</li>
<li>注：实际上一个consumer对应一个partition，不应该采用多个consumer并行消费一个partition，这可能导致潜在的单分区顺序问题。</li>
</ul>
</li>
</ul>
<h3 id="6-存储依赖-Broker-磁盘【已解决】"><a href="#6-存储依赖-Broker-磁盘【已解决】" class="headerlink" title="6. 存储依赖 Broker 磁盘【已解决】"></a>6. <strong>存储依赖 Broker 磁盘</strong>【已解决】</h3><ul>
<li>Broker 磁盘损坏 → 未消费消息可能丢失。</li>
<li><strong>解决方案</strong>：<ul>
<li>多副本机制（Replication Factor &gt; 1）</li>
<li>生产者 ACK 配置 (<code>acks=all</code>) 确保消息写入所有副本。</li>
</ul>
</li>
</ul>
<h3 id="7-重复生产【已解决】"><a href="#7-重复生产【已解决】" class="headerlink" title="7.重复生产【已解决】"></a>7.重复生产【已解决】</h3><p>在 0.11.0.0 之前，如果生产者未能收到指示消息已提交的响应，它别无选择，只能重新发送消息。这提供了至少一次传递语义，因为如果原始请求实际上已成功，则在重新发送期间消息可能会再次写入日志。从0.11.0.0开始，Kafka生产者还支持幂等传递选项，保证重新发送不会导致日志中出现重复条目。为了实现这一点，代理为每个生产者分配一个 ID，并使用生产者随每条消息发送的序列号来删除重复的消息。同样从 0.11.0.0 开始，生产者支持使用类似事务的语义将消息发送到多个主题分区的能力：即，要么所有消息都成功写入，要么没有一条消息成功写入。</p>
<h2 id="未来的计划（原论文均已实现）"><a href="#未来的计划（原论文均已实现）" class="headerlink" title="未来的计划（原论文均已实现）"></a>未来的计划（原论文均已实现）</h2><p><strong>内置消息复制</strong></p>
<ul>
<li>计划在多个 Broker 之间增加消息的内置复制，以在不可恢复的机器故障情况下保证 <strong>数据持久性和可用性</strong>。</li>
<li>希望支持 <strong>异步和同步复制</strong> 模型，让应用在生产者延迟和保证强度之间做权衡。</li>
<li>应用可以根据对持久性、可用性和吞吐量的需求选择合适的冗余级别。</li>
</ul>
<p><strong>流处理能力</strong></p>
<ul>
<li>在 Kafka 中增加流处理功能。</li>
<li>实时应用在获取消息后，通常会执行类似 <strong>窗口统计</strong>、或者 <strong>与二级存储或其他流的消息做 join</strong> 的操作。</li>
<li>在最低层，通过在发布时 <strong>按 join key 对消息进行语义分区</strong>，保证所有具有相同 key 的消息进入同一分区，从而到达同一个消费者进程。</li>
<li>这为在消费者集群上处理分布式流奠定了基础。</li>
<li>在此基础上，我们认为提供一套 <strong>流处理工具库</strong>（如各种窗口函数或 join 技术）对应用非常有帮助。</li>
</ul>
<p>上面的计划在kafka3.x之后已经实现，分别为（1）副本机制，（2）流和表的转换，可以实现使用Ksql来查找指定的消息。</p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">John Doe</div><div class="post-copyright__author_desc"></div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/')">kafka</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=kafka&amp;url=http://example.com/2025/08/12/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/kafka/&amp;pic=" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"></div></div></div><div class="post_share"><div class="social-share" data-image="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2025/08/12/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">数据结构</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__description"></div></div></div><div class="card-widget anzhiyu-right-widget" id="card-wechat" onclick="null"><div id="flip-wrapper"><div id="flip-content"><div class="face" style="background: url(https://bu.dusays.com/2023/01/13/63c02edf44033.png) center center / 100% no-repeat"></div><div class="back face" style="background: url(https://bu.dusays.com/2023/05/13/645fa415e8694.png) center center / 100% no-repeat"></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%9D%E6%AD%A5%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">初步概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E6%81%AF%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.1.</span> <span class="toc-text">消息订阅模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F%EF%BC%88Point-to-Point-Queue-%E6%A8%A1%E5%BC%8F%EF%BC%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">1. 点对点模式（Point-to-Point, Queue 模式）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E8%AE%A1%E6%9E%B6%E6%9E%84"><span class="toc-number">1.2.</span> <span class="toc-text">设计架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E5%B8%83%E5%B1%80"><span class="toc-number">1.3.</span> <span class="toc-text">存储布局</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Partition%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.1.</span> <span class="toc-text">Partition结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#message%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.2.</span> <span class="toc-text">message结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%98%E5%82%A8%E7%AD%96%E7%95%A5"><span class="toc-number">1.3.3.</span> <span class="toc-text">存储策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%BD%8D%E6%B6%88%E6%81%AF"><span class="toc-number">1.3.4.</span> <span class="toc-text">定位消息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6"><span class="toc-number">1.3.5.</span> <span class="toc-text">综合时间复杂度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE%E6%B5%81%E7%A8%8B%EF%BC%88%E5%AD%98%E5%82%A8%E8%A7%92%E5%BA%A6%EF%BC%89"><span class="toc-number">1.3.6.</span> <span class="toc-text">数据访问流程（存储角度）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%9F%E4%BA%A7%E8%80%85%E7%94%9F%E4%BA%A7"><span class="toc-number">1.4.</span> <span class="toc-text">生产者生产</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E6%B6%88%E8%B4%B9"><span class="toc-number">1.5.</span> <span class="toc-text">消费者消费</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E4%BC%A0%E8%BE%93"><span class="toc-number">1.6.</span> <span class="toc-text">高效传输</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%A0%E7%8A%B6%E6%80%81-broker"><span class="toc-number">1.7.</span> <span class="toc-text">无状态 broker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%E5%8D%8F%E8%B0%83"><span class="toc-number">1.8.</span> <span class="toc-text">分区协调</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E5%8F%91%E4%BF%9D%E9%9A%9C"><span class="toc-number">1.9.</span> <span class="toc-text">分发保障</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95"><span class="toc-number">1.10.</span> <span class="toc-text">kafka性能测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Producer-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.10.1.</span> <span class="toc-text">Producer 测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Consumer-%E6%B5%8B%E8%AF%95"><span class="toc-number">1.10.2.</span> <span class="toc-text">Consumer 测试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#kafka%E7%9A%84%E7%BC%BA%E9%99%B7"><span class="toc-number">1.11.</span> <span class="toc-text">kafka的缺陷</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%B7%A8%E5%88%86%E5%8C%BA%E6%97%A0%E6%B3%95%E4%BF%9D%E8%AF%81%E5%85%A8%E5%B1%80%E9%A1%BA%E5%BA%8F"><span class="toc-number">1.11.1.</span> <span class="toc-text">1. 跨分区无法保证全局顺序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B2%A1%E6%9C%89%E5%86%85%E7%BD%AE%E6%AD%BB%E4%BF%A1%E9%98%9F%E5%88%97%EF%BC%88DLQ%EF%BC%89"><span class="toc-number">1.11.2.</span> <span class="toc-text">2. 没有内置死信队列（DLQ）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%87%B3%E5%B0%91%E4%B8%80%E6%AC%A1%E6%8A%95%E9%80%92%EF%BC%88%E5%8F%AF%E8%83%BD%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%EF%BC%89"><span class="toc-number">1.11.3.</span> <span class="toc-text">3. 至少一次投递（可能重复消费）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%B6%88%E6%81%AF%E5%BB%B6%E8%BF%9F%E6%84%9F%E7%9F%A5%E5%8F%97%E9%99%90"><span class="toc-number">1.11.4.</span> <span class="toc-text">4. 消息延迟感知受限</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E5%8D%95%E5%88%86%E5%8C%BA%E6%80%A7%E8%83%BD%E5%8F%97%E9%99%90"><span class="toc-number">1.11.5.</span> <span class="toc-text">5. 单分区性能受限</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%AD%98%E5%82%A8%E4%BE%9D%E8%B5%96-Broker-%E7%A3%81%E7%9B%98%E3%80%90%E5%B7%B2%E8%A7%A3%E5%86%B3%E3%80%91"><span class="toc-number">1.11.6.</span> <span class="toc-text">6. 存储依赖 Broker 磁盘【已解决】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-%E9%87%8D%E5%A4%8D%E7%94%9F%E4%BA%A7%E3%80%90%E5%B7%B2%E8%A7%A3%E5%86%B3%E3%80%91"><span class="toc-number">1.11.7.</span> <span class="toc-text">7.重复生产【已解决】</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AA%E6%9D%A5%E7%9A%84%E8%AE%A1%E5%88%92%EF%BC%88%E5%8E%9F%E8%AE%BA%E6%96%87%E5%9D%87%E5%B7%B2%E5%AE%9E%E7%8E%B0%EF%BC%89"><span class="toc-number">1.12.</span> <span class="toc-text">未来的计划（原论文均已实现）</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/30/%E7%BD%91%E7%BB%9C/HTTP%E5%8D%8F%E8%AE%AE/" title="No title">No title</a><time datetime="2026-01-30T08:31:58.576Z" title="Created 2026-01-30 16:31:58">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/30/%E4%B8%AA%E4%BA%BA%E4%BB%8B%E7%BB%8D/" title="No title">No title</a><time datetime="2026-01-30T08:31:58.574Z" title="Created 2026-01-30 16:31:58">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/30/hello-world/" title="Hello World">Hello World</a><time datetime="2026-01-30T08:31:58.573Z" title="Created 2026-01-30 16:31:58">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/30/Linux/linux%E5%86%85%E6%A0%B8/" title="No title">No title</a><time datetime="2026-01-30T08:31:58.573Z" title="Created 2026-01-30 16:31:58">2026-01-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/29/Java/LWT/" title="LTW加载时织入">LTW加载时织入</a><time datetime="2026-01-29T00:50:01.000Z" title="Created 2026-01-29 08:50:01">2026-01-29</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2020 - 2026 By <a class="footer-bar-link" href="/" title="John Doe" target="_blank">John Doe</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">Articles</div><div class="length-num">47</div></a><a href="/tags/" title="tag"><div class="headline">Tags</div><div class="length-num">13</div></a><a href="/categories/" title="category"><div class="headline">Categories</div><div class="length-num">23</div></a></div><span class="sidebar-menu-item-title">Function</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="Display Mode"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>Display Mode</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Java/" style="font-size: 0.88rem;">Java<sup>1</sup></a><a href="/tags/JavaScript/" style="font-size: 0.88rem;">JavaScript<sup>1</sup></a><a href="/tags/React/" style="font-size: 0.88rem;">React<sup>1</sup></a><a href="/tags/java/" style="font-size: 0.88rem;">java<sup>2</sup></a><a href="/tags/leetcode/" style="font-size: 0.88rem;">leetcode<sup>5</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/" style="font-size: 0.88rem;">分布式<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 0.88rem;">数据库<sup>1</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BB%BC%E5%90%88/" style="font-size: 0.88rem;">数据库综合<sup>1</sup></a><a href="/tags/%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" style="font-size: 0.88rem;">最佳实践<sup>1</sup></a><a href="/tags/%E7%86%94%E6%96%AD/" style="font-size: 0.88rem;">熔断<sup>1</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" style="font-size: 0.88rem;">网络安全<sup>1</sup></a><a href="/tags/%E9%99%90%E6%B5%81/" style="font-size: 0.88rem;">限流<sup>1</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2021 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2020 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 John Doe 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>